{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f72badb",
   "metadata": {},
   "source": [
    "### Profesional way is make a coustom Fn and Call it When you want to see Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bf57c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_md(text: str):\n",
    "    from IPython.display import Markdown, display\n",
    "    display(Markdown(text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1976ecc0",
   "metadata": {},
   "source": [
    "### Loading .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ac97b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04c0672",
   "metadata": {},
   "source": [
    "### Using Google api key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3184599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7095e244",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt =[\n",
    "    (\"system\",\"you are react developer\"), # Try with and without system prompt\n",
    "    (\"user\",\"what is size of penis?\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f48716b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237f1aaf",
   "metadata": {},
   "source": [
    "> #### With the system prompt , the model genrated response in that context or according to some pre assumations  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81e9ebfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "As a React developer, my expertise is in building user interfaces with React, JavaScript, and related web technologies.\n",
       "\n",
       "I don't have information on the size of a penis, as that falls outside the scope of software development.\n",
       "\n",
       "If you have any questions about React, component design, state management, hooks, performance optimization, or anything else related to web development, I'd be happy to help!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "render_md(res.content) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b3ea790",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_ =[\n",
    "    # (\"system\",\"you are react developer\"), # Try with and without system prompt\n",
    "    (\"user\",\"what is size of penis?\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad238858",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ = llm.invoke(prompt_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81144556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Penis size varies significantly among individuals. Here's a breakdown of average sizes based on scientific studies, primarily from a 2015 meta-analysis published in the British Journal of Urology International which analyzed data from over 15,000 men:\n",
       "\n",
       "**1. Erect Length:**\n",
       "*   **Average:** Approximately **5.16 inches (13.12 cm)** when measured from the pubic bone to the tip of the glans (head) on the top side.\n",
       "*   **Range:** Most men fall between **4.5 and 6 inches (11.4 to 15.2 cm)**.\n",
       "\n",
       "**2. Erect Girth (Circumference):**\n",
       "*   **Average:** Approximately **4.59 inches (11.66 cm)** around the middle of the shaft.\n",
       "*   **Range:** Most men fall between **4 and 5 inches (10.2 to 12.7 cm)**.\n",
       "\n",
       "**3. Flaccid Length:**\n",
       "*   **Average:** Approximately **3.61 inches (9.16 cm)**.\n",
       "*   **Variability:** Flaccid size is highly variable and often does not correlate with erect size. Some penises appear small when flaccid (\"growers\") but become much larger when erect, while others appear larger when flaccid (\"showers\") but don't change as much in size when erect.\n",
       "\n",
       "**4. Stretched Flaccid Length:**\n",
       "*   **Average:** Approximately **5.16 inches (13.24 cm)**. This measurement is often used by doctors to assess potential for growth or to compare with erect length.\n",
       "\n",
       "**Important Considerations:**\n",
       "\n",
       "*   **Measurement Method:** For accurate measurement, especially for erect length, a ruler should be pressed firmly against the pubic bone to account for any fat pad.\n",
       "*   **What's \"Normal\":** There's a wide range of what's considered normal. The vast majority of men fall within the average ranges mentioned above.\n",
       "*   **Micropenis:** A penis is medically classified as a \"micropenis\" if its erect length is less than 2.8 inches (7 cm). This is a rare condition.\n",
       "*   **Factors That Do NOT Influence Size:** Research has consistently shown no correlation between penis size and factors like race/ethnicity, shoe size, hand size, nose size, or height.\n",
       "*   **Functionality Over Size:** For both urination and sexual activity, the functionality and health of the penis, along with communication and technique, are far more important than its size. The outer third of the vagina is where most nerve endings are concentrated for pleasure during intercourse.\n",
       "\n",
       "Many men experience anxiety about their penis size, often due to unrealistic portrayals in media or comparisons. If you have concerns about penis size, it's best to consult with a healthcare professional."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "render_md(res_.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6179934",
   "metadata": {},
   "source": [
    "##  Using Open Ai Api Key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9a0db69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "oak = ChatOpenAI(base_url=\"https://openrouter.ai/api/v1\",model=\"openai/gpt-oss-20b:free\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e9dd16f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Provider returned error', 'code': 429, 'metadata': {'raw': 'openai/gpt-oss-20b:free is temporarily rate-limited upstream. Please retry shortly, or add your own key to accumulate your rate limits: https://openrouter.ai/settings/integrations', 'provider_name': 'OpenInference'}}, 'user_id': 'user_37sMjw10mX3NZTwKCjSblT5yWiZ'}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m res1 = \u001b[43moak\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\BT24F05F057\\SEM-4\\cumCode\\GenAi\\GENAI_SERIES\\myvenv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:402\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    390\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    395\u001b[39m     **kwargs: Any,\n\u001b[32m    396\u001b[39m ) -> AIMessage:\n\u001b[32m    397\u001b[39m     config = ensure_config(config)\n\u001b[32m    398\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    399\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    400\u001b[39m         cast(\n\u001b[32m    401\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m402\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    412\u001b[39m         ).message,\n\u001b[32m    413\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\BT24F05F057\\SEM-4\\cumCode\\GenAi\\GENAI_SERIES\\myvenv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1121\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1112\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1114\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1118\u001b[39m     **kwargs: Any,\n\u001b[32m   1119\u001b[39m ) -> LLMResult:\n\u001b[32m   1120\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\BT24F05F057\\SEM-4\\cumCode\\GenAi\\GENAI_SERIES\\myvenv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:931\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    929\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    930\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m931\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    937\u001b[39m         )\n\u001b[32m    938\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    939\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\BT24F05F057\\SEM-4\\cumCode\\GenAi\\GENAI_SERIES\\myvenv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1225\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1223\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1225\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1226\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1227\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1229\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\BT24F05F057\\SEM-4\\cumCode\\GenAi\\GENAI_SERIES\\myvenv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1380\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1378\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[33m\"\u001b[39m\u001b[33mhttp_response\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1379\u001b[39m         e.response = raw_response.http_response  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1380\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   1381\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1382\u001b[39m     \u001b[38;5;28mself\u001b[39m.include_response_headers\n\u001b[32m   1383\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1384\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1385\u001b[39m ):\n\u001b[32m   1386\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\BT24F05F057\\SEM-4\\cumCode\\GenAi\\GENAI_SERIES\\myvenv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1375\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1368\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _construct_lc_result_from_responses_api(\n\u001b[32m   1369\u001b[39m             response,\n\u001b[32m   1370\u001b[39m             schema=original_schema_obj,\n\u001b[32m   1371\u001b[39m             metadata=generation_info,\n\u001b[32m   1372\u001b[39m             output_version=\u001b[38;5;28mself\u001b[39m.output_version,\n\u001b[32m   1373\u001b[39m         )\n\u001b[32m   1374\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1375\u001b[39m         raw_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_raw_response\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1376\u001b[39m         response = raw_response.parse()\n\u001b[32m   1377\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\BT24F05F057\\SEM-4\\cumCode\\GenAi\\GENAI_SERIES\\myvenv\\Lib\\site-packages\\openai\\_legacy_response.py:364\u001b[39m, in \u001b[36mto_raw_response_wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m extra_headers[RAW_RESPONSE_HEADER] = \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    362\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mextra_headers\u001b[39m\u001b[33m\"\u001b[39m] = extra_headers\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\BT24F05F057\\SEM-4\\cumCode\\GenAi\\GENAI_SERIES\\myvenv\\Lib\\site-packages\\openai\\_utils\\_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\BT24F05F057\\SEM-4\\cumCode\\GenAi\\GENAI_SERIES\\myvenv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1192\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1145\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1146\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1147\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1189\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m   1190\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1191\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1198\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1199\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1200\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1201\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1203\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1204\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1205\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1206\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1207\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1208\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1209\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1210\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1211\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1212\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1213\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_retention\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_retention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1214\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1215\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1216\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1217\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1218\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1219\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1220\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1221\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1225\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1226\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1227\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1228\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1229\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1230\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1231\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1232\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1233\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1236\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1237\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1238\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1242\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\BT24F05F057\\SEM-4\\cumCode\\GenAi\\GENAI_SERIES\\myvenv\\Lib\\site-packages\\openai\\_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\BT24F05F057\\SEM-4\\cumCode\\GenAi\\GENAI_SERIES\\myvenv\\Lib\\site-packages\\openai\\_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'Provider returned error', 'code': 429, 'metadata': {'raw': 'openai/gpt-oss-20b:free is temporarily rate-limited upstream. Please retry shortly, or add your own key to accumulate your rate limits: https://openrouter.ai/settings/integrations', 'provider_name': 'OpenInference'}}, 'user_id': 'user_37sMjw10mX3NZTwKCjSblT5yWiZ'}"
     ]
    }
   ],
   "source": [
    "res1 = oak.invoke(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33ee1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = oak.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ce0fe7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt3 = [\n",
    "    # (\"system\",\"you are a doctor of eyes\"),\n",
    "    (\"user\",\"how to run python code in terminal ?\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9ad3ca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "res3 = oak.invoke(prompt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8ed6c7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Below is a quick‑start guide for running Python code from a terminal (also called a command‑line interface or shell).  \n",
       "I’ll cover the most common scenarios:\n",
       "\n",
       "| What you want to do | How to do it | Example |\n",
       "|---------------------|--------------|---------|\n",
       "| **Run a Python script file** | `python <script.py>` (or `python3` on macOS/Linux) | `python hello.py` |\n",
       "| **Run a one‑liner or a short snippet** | `python -c \"<code>\"` | `python -c \"print('Hello, world!')\"` |\n",
       "| **Run a module as a script** | `python -m <module>` | `python -m http.server` |\n",
       "| **Run a script with arguments** | `python script.py arg1 arg2` | `python process.py input.txt output.txt` |\n",
       "| **Run the interactive REPL** | `python` (or `python3`) | `python` → `>>>` |\n",
       "| **Run a script that has a shebang (`#!/usr/bin/env python3`)** | Make it executable and run it directly | `chmod +x script.py && ./script.py` |\n",
       "| **Run a script inside a virtual environment** | Activate the venv, then run | `source venv/bin/activate && python script.py` |\n",
       "\n",
       "---\n",
       "\n",
       "## 1. Open a Terminal\n",
       "\n",
       "- **Windows**: Press `Win + R`, type `cmd` or `powershell`, and hit Enter.  \n",
       "  (You can also use the newer Windows Terminal or Git Bash if you have it installed.)\n",
       "- **macOS**: `Cmd + Space` → type `Terminal` → Enter.  \n",
       "- **Linux**: `Ctrl + Alt + T` or search for “Terminal” in your desktop environment.\n",
       "\n",
       "---\n",
       "\n",
       "## 2. Verify Python is Installed\n",
       "\n",
       "```bash\n",
       "python --version\n",
       "# or\n",
       "python3 --version\n",
       "```\n",
       "\n",
       "You should see something like `Python 3.11.4`.  \n",
       "If you get an error, install Python from <https://www.python.org/downloads/> or use your package manager (`apt`, `brew`, `choco`, etc.).\n",
       "\n",
       "---\n",
       "\n",
       "## 3. Create a Simple Python Script\n",
       "\n",
       "Create a file called `hello.py`:\n",
       "\n",
       "```python\n",
       "# hello.py\n",
       "print(\"Hello, world!\")\n",
       "```\n",
       "\n",
       "Save it in a folder, e.g., `~/projects/python`.\n",
       "\n",
       "---\n",
       "\n",
       "## 4. Navigate to the Script’s Directory\n",
       "\n",
       "```bash\n",
       "cd ~/projects/python\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "## 5. Run the Script\n",
       "\n",
       "```bash\n",
       "python hello.py\n",
       "# or\n",
       "python3 hello.py   # on macOS/Linux if `python` points to Python 2\n",
       "```\n",
       "\n",
       "You should see:\n",
       "\n",
       "```\n",
       "Hello, world!\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "## 6. Running Code Directly from the Command Line\n",
       "\n",
       "If you don’t want to create a file, you can run a snippet directly:\n",
       "\n",
       "```bash\n",
       "python -c \"print('Hello from the command line!')\"\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "## 7. Running a Module\n",
       "\n",
       "Python ships with many useful modules that can be run directly. For example, to start a simple HTTP server:\n",
       "\n",
       "```bash\n",
       "python -m http.server 8000\n",
       "```\n",
       "\n",
       "Open `http://localhost:8000` in a browser to see the directory listing.\n",
       "\n",
       "---\n",
       "\n",
       "## 8. Passing Arguments to a Script\n",
       "\n",
       "Modify `hello.py`:\n",
       "\n",
       "```python\n",
       "import sys\n",
       "\n",
       "if __name__ == \"__main__\":\n",
       "    print(\"Arguments:\", sys.argv[1:])\n",
       "```\n",
       "\n",
       "Run it:\n",
       "\n",
       "```bash\n",
       "python hello.py foo bar\n",
       "```\n",
       "\n",
       "Output:\n",
       "\n",
       "```\n",
       "Arguments: ['foo', 'bar']\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "## 9. Using a Virtual Environment (Optional but Recommended)\n",
       "\n",
       "```bash\n",
       "# Create a virtual environment\n",
       "python -m venv venv\n",
       "\n",
       "# Activate it\n",
       "# Windows\n",
       "venv\\Scripts\\activate\n",
       "# macOS/Linux\n",
       "source venv/bin/activate\n",
       "\n",
       "# Install packages\n",
       "pip install requests\n",
       "\n",
       "# Run your script\n",
       "python hello.py\n",
       "```\n",
       "\n",
       "When you’re done, deactivate:\n",
       "\n",
       "```bash\n",
       "deactivate\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "## 10. Making a Script Executable (Unix/macOS)\n",
       "\n",
       "Add a shebang line at the top of `hello.py`:\n",
       "\n",
       "```python\n",
       "#!/usr/bin/env python3\n",
       "print(\"Hello, world!\")\n",
       "```\n",
       "\n",
       "Make it executable:\n",
       "\n",
       "```bash\n",
       "chmod +x hello.py\n",
       "```\n",
       "\n",
       "Now you can run it directly:\n",
       "\n",
       "```bash\n",
       "./hello.py\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "## 11. Common Pitfalls & Tips\n",
       "\n",
       "| Issue | Fix |\n",
       "|-------|-----|\n",
       "| `python` runs Python 2 on some systems | Use `python3` instead. |\n",
       "| “Permission denied” when running a script | `chmod +x script.py` (Unix) |\n",
       "| “ModuleNotFoundError” | Install the module with `pip install <module>` or activate the correct virtual environment. |\n",
       "| “SyntaxError: invalid syntax” | Make sure you’re using the correct Python version for the code. |\n",
       "\n",
       "---\n",
       "\n",
       "### Quick Reference Cheat Sheet\n",
       "\n",
       "```bash\n",
       "# Check Python version\n",
       "python --version\n",
       "python3 --version\n",
       "\n",
       "# Run a script\n",
       "python script.py\n",
       "python3 script.py\n",
       "\n",
       "# Run a one‑liner\n",
       "python -c \"print('Hi')\"\n",
       "\n",
       "# Run a module\n",
       "python -m module_name\n",
       "\n",
       "# Run with arguments\n",
       "python script.py arg1 arg2\n",
       "\n",
       "# Activate virtualenv (Windows)\n",
       "venv\\Scripts\\activate\n",
       "\n",
       "# Activate virtualenv (macOS/Linux)\n",
       "source venv/bin/activate\n",
       "\n",
       "# Deactivate virtualenv\n",
       "deactivate\n",
       "```\n",
       "\n",
       "That’s it! Once you’re comfortable with these commands, you’ll be able to run almost any Python code from the terminal. Happy coding!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "render_md(res3.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "65b97051",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt3_ = [\n",
    "    (\"system\",\"you are a doctor of eyes\"),\n",
    "    (\"user\",\"how to run python code in terminal ?\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2ab052a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "res3_ = oak.invoke(prompt3_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f06e923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Below is a quick‑start guide for running Python code from a terminal (command‑line) on Windows, macOS, and Linux.  \n",
       "Feel free to skip the parts that already apply to your system.\n",
       "\n",
       "---\n",
       "\n",
       "## 1.  Make sure Python is installed\n",
       "\n",
       "| OS | How to check | How to install |\n",
       "|----|--------------|----------------|\n",
       "| **Windows** | `python --version` or `py --version` | Download the installer from <https://www.python.org/downloads/windows/> and run it.  Make sure to tick **Add Python to PATH**. |\n",
       "| **macOS** | `python3 --version` | macOS ships with Python 2.7, so install the latest Python 3 from <https://www.python.org/downloads/macos/> or via Homebrew: `brew install python`. |\n",
       "| **Linux** | `python3 --version` | Most distros ship Python 3.  If not, use your package manager, e.g. `sudo apt install python3` (Debian/Ubuntu) or `sudo dnf install python3` (Fedora). |\n",
       "\n",
       "> **Tip:** If you have both Python 2 and Python 3, use `python3` (or `py -3` on Windows) to invoke Python 3.\n",
       "\n",
       "---\n",
       "\n",
       "## 2.  Create a simple Python script\n",
       "\n",
       "1. Open a text editor (Notepad, VS Code, Vim, etc.).\n",
       "2. Paste the following code:\n",
       "\n",
       "```python\n",
       "# hello.py\n",
       "print(\"Hello, world!\")\n",
       "```\n",
       "\n",
       "3. Save the file as `hello.py` in a folder you can reach from the terminal (e.g., `~/projects/` or `C:\\Users\\<you>\\Desktop\\`).\n",
       "\n",
       "---\n",
       "\n",
       "## 3.  Open a terminal / command prompt\n",
       "\n",
       "| OS | Shortcut |\n",
       "|----|----------|\n",
       "| **Windows** | `Win + R`, type `cmd` or `powershell`, press **Enter** |\n",
       "| **macOS** | `Cmd + Space`, type `Terminal`, press **Enter** |\n",
       "| **Linux** | `Ctrl + Alt + T` (or search for “Terminal”) |\n",
       "\n",
       "---\n",
       "\n",
       "## 4.  Navigate to the script’s directory\n",
       "\n",
       "```bash\n",
       "# Example: script is on the Desktop\n",
       "cd ~/Desktop          # macOS / Linux\n",
       "cd C:\\Users\\<you>\\Desktop   # Windows (cmd)\n",
       "```\n",
       "\n",
       "You can verify you’re in the right folder with `ls` (macOS/Linux) or `dir` (Windows).\n",
       "\n",
       "---\n",
       "\n",
       "## 5.  Run the script\n",
       "\n",
       "```bash\n",
       "# macOS / Linux\n",
       "python3 hello.py\n",
       "\n",
       "# Windows\n",
       "python hello.py          # or\n",
       "py hello.py\n",
       "```\n",
       "\n",
       "You should see:\n",
       "\n",
       "```\n",
       "Hello, world!\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "## 6.  Running code without a file\n",
       "\n",
       "### a.  One‑liner\n",
       "\n",
       "```bash\n",
       "python3 -c \"print('Hello from the command line!')\"\n",
       "```\n",
       "\n",
       "### b.  Inline script (works on all OS)\n",
       "\n",
       "```bash\n",
       "python3 - <<'EOF'\n",
       "print(\"Hello from a here‑document\")\n",
       "for i in range(3):\n",
       "    print(i)\n",
       "EOF\n",
       "```\n",
       "\n",
       "### c.  Pipe a file into Python\n",
       "\n",
       "```bash\n",
       "cat hello.py | python3\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "## 7.  Interactive mode (REPL)\n",
       "\n",
       "Just type `python3` (or `python` on Windows) and press **Enter**.  \n",
       "You’ll see a prompt `>>>` where you can type Python commands interactively.\n",
       "\n",
       "```bash\n",
       "$ python3\n",
       "Python 3.11.4 (main, Jun  5 2024, 12:34:56) \n",
       ">>> 2 + 2\n",
       "4\n",
       ">>> exit()\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "## 8.  Using a virtual environment (recommended for projects)\n",
       "\n",
       "```bash\n",
       "# Create a new directory for your project\n",
       "mkdir myproject && cd myproject\n",
       "\n",
       "# Create a virtual environment\n",
       "python3 -m venv venv\n",
       "\n",
       "# Activate it\n",
       "# macOS / Linux\n",
       "source venv/bin/activate\n",
       "# Windows (cmd)\n",
       "venv\\Scripts\\activate.bat\n",
       "# Windows (PowerShell)\n",
       "venv\\Scripts\\Activate.ps1\n",
       "\n",
       "# Now install packages locally\n",
       "pip install requests\n",
       "\n",
       "# Run your script\n",
       "python hello.py\n",
       "```\n",
       "\n",
       "When you’re done, deactivate the environment:\n",
       "\n",
       "```bash\n",
       "deactivate\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "## 9.  Common pitfalls\n",
       "\n",
       "| Symptom | Likely cause | Fix |\n",
       "|---------|--------------|-----|\n",
       "| `python: command not found` | Python not on PATH | Re‑install Python and check “Add to PATH” (Windows) or add `export PATH=\"/usr/local/bin:$PATH\"` (macOS/Linux). |\n",
       "| `SyntaxError: invalid syntax` | Wrong Python version (e.g., using Python 2 for a 3‑only script) | Use `python3` instead of `python`. |\n",
       "| `ModuleNotFoundError: No module named '...'` | Package not installed in current environment | `pip install <package>` inside the active virtual environment. |\n",
       "\n",
       "---\n",
       "\n",
       "## 10.  Quick cheat‑sheet\n",
       "\n",
       "| Command | What it does |\n",
       "|---------|--------------|\n",
       "| `python3 --version` | Show Python version |\n",
       "| `python3 -m pip install <pkg>` | Install a package |\n",
       "| `python3 -m venv venv` | Create a virtual environment |\n",
       "| `source venv/bin/activate` | Activate venv (macOS/Linux) |\n",
       "| `venv\\Scripts\\activate.bat` | Activate venv (Windows cmd) |\n",
       "| `python3 script.py` | Run a script |\n",
       "| `python3 -c \"code\"` | Run a one‑liner |\n",
       "| `python3 - <<'EOF' ... EOF` | Run a block of code from the terminal |\n",
       "\n",
       "---\n",
       "\n",
       "### 🎉 You’re ready to run Python from the terminal! 🎉\n",
       "\n",
       "If you hit any snags, just let me know the exact error message or what you’re trying to do, and I’ll help troubleshoot. Happy coding!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "render_md(res3_.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
